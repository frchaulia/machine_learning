{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frcaulia/machine_learning/blob/main/Module_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWiNTcRa3RD7"
      },
      "source": [
        "# **Faricha Aulia âœ¨**\n",
        "Machine Learning Course : Module 10 Lab Work Assignment\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01ISZDqj7J27"
      },
      "source": [
        "### **Set Up**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQgPXzjR7Pdj"
      },
      "source": [
        "Import library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cHXT-yEP2xAK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuG_xUcY7VZu"
      },
      "source": [
        "Download Dataset Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTJ2rw2-5aJJ",
        "outputId": "c153af32-8218-499a-90a0-d27228c2fdc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1r2wIb57Zvj"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpQVtNAA5p-t",
        "outputId": "3e06cb4e-9e51-4a7b-bfb5-e80a6ebf30be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qka4ByCS5zFg",
        "outputId": "d013f281-26d6-4091-d13d-9b2d3777ff26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_yG_ES-51mv",
        "outputId": "f5e62b5f-4b7d-4ae2-e0d8-43e81e2fed03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSwk_STi7bEr"
      },
      "source": [
        "### **Text Processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VweYwNOV7iGM"
      },
      "source": [
        "Vectorize Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6emr3WD-54t2",
        "outputId": "499434a0-730a-43d4-f741-557a3d9252c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg','xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hijhggkc6Jwa"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab),mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaOhdQrZ6QlB",
        "outputId": "98d05711-2127-41e7-f253-ef319567aa88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2JN5Kfft6ZUz"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am7DW0El6kLP",
        "outputId": "95dff1bf-80ca-4e06-dca8-9044e4533ab4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFlvWMWr6n4d",
        "outputId": "532fd074-b93d-4d3d-e49f-7e9fb49a31a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars,axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbJGh5MH7qfY"
      },
      "source": [
        "Creating the Training Set and Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA9cYmoV683o",
        "outputId": "bccc3797-010d-4e5c-de0e-f4505103cfee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jtrRwc0z7Axd"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7NKvsHa7-kZ",
        "outputId": "54eee23c-236d-4792-9d8e-ee6793a9fe5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "H7TIJw8S8E0H"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wpv8hXx9MS7",
        "outputId": "84d7ad15-ff84-4315-dc10-d62f18f9d21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AYpJLXcL_n5V"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(ids_from_chars(ids), axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2DiYO3R_tH7",
        "outputId": "03737d6a-f3e3-49c1-da62-2b2363c4c619"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "U1ErDDW09Nr7"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmscQg35-YiW",
        "outputId": "a05ec774-19a1-4eb6-f4d2-d02fc2effba6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zlVqkFu9-cOH"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdJU1zrM-iAx",
        "outputId": "31eaaec3-fd22-47df-cd4f-7286cf4c1359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "InputÂ : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"InputÂ :\", text_from_ids(input_example))\n",
        "  print(\"Target:\", text_from_ids(target_example))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v9eQ9fhAFgP"
      },
      "source": [
        "Creating Batch Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBkN-enJABAe",
        "outputId": "ca977108-0b45-46cc-ece4-53a7cb57192a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3nrIbHuAQsh"
      },
      "source": [
        "### **Create a Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ETUk3tvFAWnD"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "a5_cj2YmAmsz"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UTzBDzulArY_"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX-zzL_yAs3i"
      },
      "source": [
        "### **Test The Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZsLoD6GAx27",
        "outputId": "119c85e5-41f3-4140-aa17-31ab581a83ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2qV0x4SA1gH",
        "outputId": "4dc11b9d-8c54-4bea-8091-52cafb0c519f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "klO-qpL5A5U8"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmRDsUl1A-WJ",
        "outputId": "640709e3-1140-45b5-fc34-9a77458a947f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([33, 49,  9, 51, 35,  1, 16, 36,  6, 41,  3, 21, 38, 10, 29, 16, 22,\n",
              "       45, 14, 29, 61,  5, 38, 44, 18, 42, 17, 30, 20,  1, 38, 28, 12, 41,\n",
              "       30, 18,  2, 15,  6,  9, 36, 60, 57, 57, 51, 32, 12, 43, 51, 24, 16,\n",
              "       30, 27, 57, 34, 40, 34,  6, 45, 25, 13, 40,  2, 12, 57, 42, 33, 25,\n",
              "       36, 19, 17, 15, 12, 27, 26, 12,  0, 27, 60, 35, 48, 44, 30, 14, 60,\n",
              "       44,  5, 16, 26, 51, 49, 49, 52,  7, 38, 16, 28, 57, 63, 29])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bX8IvlBBAMw",
        "outputId": "84434d7e-9ff8-421d-fd79-79573af76fce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'ge, whereof the least\\nIs not this suit of mine, that thou declare\\nWhat incidency thou dost guess of '\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"Tj.lV\\nCW'b!HY3PCIfAPv&YeEcDQG\\nYO;bQE B'.WurrlS;dlKCQNrUaU'fL?a ;rcTLWFDB;NM;[UNK]NuVieQAue&CMljjm,YCOrxP\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]))\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0kXjg5-Gie-"
      },
      "source": [
        "## **Labwork Assignment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qE3I1VgiNFgR"
      },
      "source": [
        "The training procedure in practical 2 is a simple procedure that does not give you much control. This model uses 'teacher-forcing,' which prevents bad predictions from being fed back into the model, so the model never learns to recover from mistakes. So, after you've seen how to run the model manually, you'll implement a custom training loop. This provides a starting point if, for example, you want to implement curriculum learning to help stabilize the open-loop model's output. The most crucial part of the custom training loop is the training step function.\n",
        "\n",
        "Use tf.GradientTape to track gradient values. You can learn more about this approach by reading the eager execution guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DTlyXVAqIWDw"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "b0SS7av3K9G4"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(vocab_size=len(ids_from_chars.get_vocabulary()), embedding_dim=embedding_dim, rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "vvGI9-BJLGnY"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFXKSIhFLKNj",
        "outputId": "4b8d7c2f-08d2-4815-b080-467fa59c1d67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 21s 63ms/step - loss: 2.7169\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78e4ad7636d0>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dfMC7rpLKwF",
        "outputId": "c22520d8-2392-43c8-9392-65e8c578a8c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Epoch 1 Batch 0 Loss 1.3586\n",
            "Epoch 1 Batch 50 Loss 1.3822\n",
            "Epoch 1 Batch 100 Loss 1.3158\n",
            "Epoch 1 Batch 150 Loss 1.3332\n",
            "\n",
            "Epoch 1 Loss: 1.3290\n",
            "Time taken for 1 epoch 12.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.2373\n",
            "Epoch 2 Batch 50 Loss 1.2869\n",
            "Epoch 2 Batch 100 Loss 1.2799\n",
            "Epoch 2 Batch 150 Loss 1.3199\n",
            "\n",
            "Epoch 2 Loss: 1.2840\n",
            "Time taken for 1 epoch 12.57 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.1979\n",
            "Epoch 3 Batch 50 Loss 1.2493\n",
            "Epoch 3 Batch 100 Loss 1.2432\n",
            "Epoch 3 Batch 150 Loss 1.2140\n",
            "\n",
            "Epoch 3 Loss: 1.2424\n",
            "Time taken for 1 epoch 11.89 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.1778\n",
            "Epoch 4 Batch 50 Loss 1.1953\n",
            "Epoch 4 Batch 100 Loss 1.2413\n",
            "Epoch 4 Batch 150 Loss 1.2090\n",
            "\n",
            "Epoch 4 Loss: 1.2024\n",
            "Time taken for 1 epoch 12.15 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.1106\n",
            "Epoch 5 Batch 50 Loss 1.1714\n",
            "Epoch 5 Batch 100 Loss 1.1810\n",
            "Epoch 5 Batch 150 Loss 1.1659\n",
            "\n",
            "Epoch 5 Loss: 1.1612\n",
            "Time taken for 1 epoch 11.79 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.1078\n",
            "Epoch 6 Batch 50 Loss 1.1525\n",
            "Epoch 6 Batch 100 Loss 1.1172\n",
            "Epoch 6 Batch 150 Loss 1.1200\n",
            "\n",
            "Epoch 6 Loss: 1.1198\n",
            "Time taken for 1 epoch 11.36 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.0427\n",
            "Epoch 7 Batch 50 Loss 1.0448\n",
            "Epoch 7 Batch 100 Loss 1.0707\n",
            "Epoch 7 Batch 150 Loss 1.0992\n",
            "\n",
            "Epoch 7 Loss: 1.0762\n",
            "Time taken for 1 epoch 11.29 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 0.9818\n",
            "Epoch 8 Batch 50 Loss 0.9987\n",
            "Epoch 8 Batch 100 Loss 1.0091\n",
            "Epoch 8 Batch 150 Loss 1.0352\n",
            "\n",
            "Epoch 8 Loss: 1.0300\n",
            "Time taken for 1 epoch 12.08 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 0.9602\n",
            "Epoch 9 Batch 50 Loss 0.9703\n",
            "Epoch 9 Batch 100 Loss 0.9900\n",
            "Epoch 9 Batch 150 Loss 1.0096\n",
            "\n",
            "Epoch 9 Loss: 0.9805\n",
            "Time taken for 1 epoch 13.05 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 0.8924\n",
            "Epoch 10 Batch 50 Loss 0.9289\n",
            "Epoch 10 Batch 100 Loss 0.9437\n",
            "Epoch 10 Batch 150 Loss 0.9802\n",
            "\n",
            "Epoch 10 Loss: 0.9291\n",
            "Time taken for 1 epoch 13.31 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define checkpoint_prefix with a path in Google Drive\n",
        "checkpoint_prefix = \"/content/drive/MyDrive/your/checkpoint/path/model_checkpoint_{epoch}\"\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX1odEPzNNTN"
      },
      "source": [
        "## **Run the code above and tell me how it differs from lab 2?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0llmQFOzM4s_"
      },
      "source": [
        "The difference between Practicum 2 and Assignment lies in their training procedures.\n",
        "\n",
        "1. Practicum 2 (Classic Training Loop):\n",
        "  * Uses the model.fit function to train the model (standard training approach commonly used in TensorFlow)\n",
        "  * Loss is calculated with 'tf.losses.SparseCategoricalCrossentropy', defined separately but not used in the training process. Instructions to print the loss are present but might not be suitable in the given context.\n",
        "  * The training process uses model.fit by providing the dataset and the number of epochs.\n",
        "\n",
        "2. Assignment (Custom Training Loop):\n",
        "  * Employs a more customized training approach. It involves creating a custom class, CustomTraining, which overrides the train_step method.\n",
        "  * Inside train_step, the loss is computed with the self.loss function, likely an integrated loss function within the model. Gradients are calculated and applied to the model more explicitly.\n",
        "  * The training process uses a specific loop that processes batches of the dataset. Each batch is processed manually by calling train_step on the custom model, and the mean loss is computed for each epoch.\n",
        "\n",
        "Conclusion : Code in the assignment provides more flexibility and control over the training procedure. We can specify steps such as loss calculation and gradient computation more directly. While Code 1 is more user-friendly, it may not offer the same level of control as Code 2."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNdpOLqeO4t0WKDWNIsQR2e",
      "collapsed_sections": [
        "01ISZDqj7J27",
        "qSwk_STi7bEr",
        "d3nrIbHuAQsh",
        "gX-zzL_yAs3i"
      ],
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
